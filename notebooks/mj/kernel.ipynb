{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/batman/kaggle/kaggle-ashrae-DSR\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/batman/kaggle/kaggle-ashrae-DSR')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Sun Jun 10 10:32:09 2018\\n\\n@author: m.jones\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Jun 10 10:32:09 2018\n",
    "\n",
    "@author: m.jones\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "CONTROL_PARAMS = {\n",
    "    # The machine running, either LOCAL or KAGGLE\n",
    "    # 'DEPLOYMENT': None,\n",
    "\n",
    "    # The type of run:\n",
    "    # SIMPLE\n",
    "    # KERNEL (Default)\n",
    "    # SEARCH\n",
    "    # 'RUN_TYPE' : None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "title": "==========================================================================="
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:31:17 : Logging started\n",
      "2019-11-24 12:31:17 : Kernel started 2019-11-24 12:31:17.108349\n"
     ]
    }
   ],
   "source": [
    "# Logging\n",
    "# =============================================================================\n",
    "import sys\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "\n",
    "# Set level\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create formatter\n",
    "FORMAT = \"%(asctime)s : %(message)s\"\n",
    "DATE_FMT = \"%Y-%m-%d %H:%M:%S\"\n",
    "formatter = logging.Formatter(FORMAT, DATE_FMT)\n",
    "\n",
    "# Create handler and assign\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "handler.setFormatter(formatter)\n",
    "logger.handlers = [handler]\n",
    "\n",
    "CONTROL_PARAMS['START_TIME'] = datetime.datetime.now()\n",
    "logging.info(\"Logging started\")\n",
    "\n",
    "logging.info(\"Kernel started {}\".format(CONTROL_PARAMS['START_TIME']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "title": "==========================================================================="
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "# =============================================================================\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import zipfile\n",
    "import gc\n",
    "import time\n",
    "from pprint import pprint\n",
    "from functools import reduce\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import yaml\n",
    "import inspect\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "title": "==========================================================================="
   },
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "# =============================================================================\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "title": "==========================================================================="
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.17.4 as np\n",
      "pandas 0.25.3 as pd\n",
      "sklearn 0.21.3 as sk\n",
      "lightgbm 2.3.0\n",
      "xgboost 0.90\n",
      "catboost 0.19.1\n"
     ]
    }
   ],
   "source": [
    "# ML imports\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "print('numpy {} as np'.format(np.__version__))\n",
    "import pandas as pd\n",
    "print('pandas {} as pd'.format(pd.__version__))\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import sklearn as sk\n",
    "print('sklearn {} as sk'.format(sk.__version__))\n",
    "\n",
    "import sklearn.preprocessing\n",
    "import sklearn.metrics\n",
    "import sklearn.linear_model\n",
    "import sklearn.pipeline\n",
    "import sklearn.model_selection\n",
    "import sklearn.ensemble\n",
    "import sklearn.feature_extraction\n",
    "import sklearn.decomposition\n",
    "import sklearn.compose\n",
    "import sklearn.utils\n",
    "\n",
    "# Models\n",
    "import lightgbm as lgb\n",
    "print(\"lightgbm\", lgb.__version__)\n",
    "import xgboost as xgb\n",
    "print(\"xgboost\", xgb.__version__)\n",
    "# from catboost import CatBoostClassifier\n",
    "import catboost as catb\n",
    "print(\"catboost\", catb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "title": "==========================================================================="
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib 3.1.2 as mpl\n",
      "matplotlib.pyplot as plt\n",
      "seaboarn 0.9.0 as sns\n"
     ]
    }
   ],
   "source": [
    "# Plotting\n",
    "# =============================================================================\n",
    "import matplotlib as mpl\n",
    "print('matplotlib {} as mpl'.format(mpl.__version__))\n",
    "import matplotlib.pyplot as plt\n",
    "print('matplotlib.pyplot as plt'.format())\n",
    "import seaborn as sns\n",
    "print('seaboarn {} as sns'.format(sns.__version__))\n",
    "\n",
    "# from IPython.core.display import display, HTML\n",
    "\n",
    "# --- plotly ---\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\"\n",
    "# from plotly import tools, subplots\n",
    "import plotly.offline as py\n",
    "# py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
    "# Modified to support timestamp type, categorical type\n",
    "# Modified to add option to use float16 or not. feather format does not support float16.\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "\n",
    "\n",
    "def get_building(df_meter_records, bldg_id):\n",
    "    \"\"\"\n",
    "    Given the flat records for each meter-building-site\n",
    "\n",
    "    Break out a summary energy profile DF for each building with the columns;\n",
    "    Timestamp - Meter 1 - Meter 1 - Meter 1 - Meter 1\n",
    "    Renames meter columns to proper energy sources\n",
    "    \"\"\"\n",
    "\n",
    "    # Select the building records\n",
    "    bldg_df = df_meter_records[df_meter_records.loc[:, 'building_id'] == bldg_id]\n",
    "    bldg_df.drop('building_id', axis=1, inplace=True)\n",
    "    logging.info(\"Building {} with {} records over {} meters\".format(bldg_id, len(bldg_df), bldg_df['meter'].nunique()))\n",
    "\n",
    "    # Pivot the records to meter-meter-meter-meter format\n",
    "    bldg_df_pivot = bldg_df.pivot(index='timestamp', columns='meter', values='meter_reading')\n",
    "\n",
    "    # For convenience, create empty columns for missing meters\n",
    "    for meter_col in range(4):\n",
    "        if meter_col not in bldg_df_pivot.columns:\n",
    "            bldg_df_pivot[meter_col] = int(0)\n",
    "\n",
    "    # bldg_df_pivot.memory_usage().sum() / 1024 ** 2 # Size in MB\n",
    "    bldg_df_pivot.rename(columns={0: 'electricity', 1: 'chilledwater', 2: 'steam', 3: 'hotwater'}, inplace=True)\n",
    "    logging.info(\"{} to {}\".format(bldg_df_pivot.index[0], bldg_df_pivot.index[-1]))\n",
    "    assert bldg_df_pivot.index.is_monotonic_increasing\n",
    "\n",
    "    return bldg_df_pivot\n",
    "\n",
    "# for i in range(1000):\n",
    "# bldg_id = i\n",
    "# this_bldg = get_building(train_df, bldg_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_site_weather(weather_df, site_id):\n",
    "\n",
    "    # Select the building records\n",
    "    site_weather_df = weather_df[weather_df.loc[:, 'site_id'] == site_id]\n",
    "    site_weather_df.drop('site_id', axis=1, inplace=True)\n",
    "    logging.info(\"Site {} with {} records\".format(site_id, len(site_weather_df)))\n",
    "    site_weather_df.set_index('timestamp', drop=True, inplace=True)\n",
    "    logging.info(\"{} to {}\".format(site_weather_df.index[0], site_weather_df.index[-1]))\n",
    "    assert site_weather_df.index.is_monotonic_increasing\n",
    "\n",
    "    return site_weather_df\n",
    "\n",
    "# site_id = 0\n",
    "# for i in range(16):\n",
    "#     r = get_site_weather(weather_train_df,i)\n",
    "# r = weather_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    logging.debug('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            # skip datetime type or categorical type\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    logging.debug('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    logging.info('Memory decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:31:50 : Settings:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'path_data_root': PosixPath('/home/batman/kaggle/kaggle-ashrae-DSR/data/feather'), 'use_ucf': True, 'path_output': PosixPath('/home/batman/kaggle/kaggle-ashrae-DSR/output')}, 'model': {'folds': 5, 'num_rounds': 1000}, 'control': {'debug': False}}\n"
     ]
    }
   ],
   "source": [
    "class Map(dict):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "    m = Map({'first_name': 'Eduardo'}, last_name='Pool', age=24, sports=['Soccer'])\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Map, self).__init__(*args, **kwargs)\n",
    "        for arg in args:\n",
    "            if isinstance(arg, dict):\n",
    "                for k, v in arg.iteritems():\n",
    "                    self[k] = v\n",
    "\n",
    "        if kwargs:\n",
    "            for k, v in kwargs.iteritems():\n",
    "                self[k] = v\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        return self.get(attr)\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self.__setitem__(key, value)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        super(Map, self).__setitem__(key, value)\n",
    "        self.__dict__.update({key: value})\n",
    "\n",
    "    def __delattr__(self, item):\n",
    "        self.__delitem__(item)\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        super(Map, self).__delitem__(key)\n",
    "        del self.__dict__[key]\n",
    "\n",
    "# Set the environment\n",
    "SETTINGS = Map()\n",
    "SETTINGS.data = Map()\n",
    "SETTINGS.model = Map()\n",
    "\n",
    "SETTINGS.data.path_data_root = Path.cwd() / 'data' / 'feather'\n",
    "SETTINGS.data.use_ucf = True\n",
    "SETTINGS.data.path_output = Path.cwd() / 'output'\n",
    "\n",
    "SETTINGS.model.folds = 5\n",
    "SETTINGS.model.num_rounds=1000\n",
    "SETTINGS.control = Map()\n",
    "SETTINGS.control.debug = False\n",
    "\n",
    "\n",
    "logging.info(\"Settings:\".format())\n",
    "print(SETTINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Train data"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-24 12:31:51 :  *** Step 2: Load data *** \n"
     ]
    },
    {
     "ename": "ArrowIOError",
     "evalue": "Failed to open local file '/home/batman/kaggle/kaggle-ashrae-DSR/data/feather/train.feather', error: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowIOError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-82ed3ef67979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETTINGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_data_root\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'train.feather'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded: train_df {} with {} buildings, {:0.1f} MB\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'building_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/kaggle-ashrae-DSR-G_JqcSxd/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/kaggle-ashrae-DSR-G_JqcSxd/lib/python3.6/site-packages/pandas/io/feather_format.py\u001b[0m in \u001b[0;36mread_feather\u001b[0;34m(path, columns, use_threads)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint_use_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/kaggle-ashrae-DSR-G_JqcSxd/lib/python3.6/site-packages/pyarrow/feather.py\u001b[0m in \u001b[0;36mread_feather\u001b[0;34m(source, columns, use_threads)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \"\"\"\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatherReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/kaggle-ashrae-DSR-G_JqcSxd/lib/python3.6/site-packages/pyarrow/feather.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0m_check_pandas_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/kaggle-ashrae-DSR-G_JqcSxd/lib/python3.6/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/kaggle-ashrae-DSR-G_JqcSxd/lib/python3.6/site-packages/pyarrow/io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.get_reader\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/kaggle-ashrae-DSR-G_JqcSxd/lib/python3.6/site-packages/pyarrow/io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._get_native_file\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/kaggle-ashrae-DSR-G_JqcSxd/lib/python3.6/site-packages/pyarrow/io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.memory_map\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/kaggle-ashrae-DSR-G_JqcSxd/lib/python3.6/site-packages/pyarrow/io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.MemoryMappedFile._open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/kaggle-ashrae-DSR-G_JqcSxd/lib/python3.6/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowIOError\u001b[0m: Failed to open local file '/home/batman/kaggle/kaggle-ashrae-DSR/data/feather/train.feather', error: No such file or directory"
     ]
    }
   ],
   "source": [
    "logging.info(\" *** Step 2: Load data *** \".format())\n",
    "\n",
    "# Train\n",
    "train_df = pd.read_feather(SETTINGS.data.path_data_root / 'train.feather')\n",
    "logging.info(\"Loaded: train_df {} with {} buildings, {:0.1f} MB\".format(train_df.shape, train_df.loc[:, 'building_id'].nunique(), train_df.memory_usage().sum() / 1024 ** 2))\n",
    "r1 = train_df.head()\n",
    "train_df = reduce_mem_usage(train_df)\n",
    "\n",
    "# Test\n",
    "test_df = pd.read_feather(SETTINGS.data.path_data_root / 'test.feather')\n",
    "logging.info(\"Loaded: test_df {} with {} buildings, {:0.1f} MB\".format(test_df.shape, test_df.loc[:, 'building_id'].nunique(), test_df.memory_usage().sum() / 1024 ** 2))\n",
    "r2 = test_df.head()\n",
    "test_df = reduce_mem_usage(test_df)\n",
    "\n",
    "# Weather train\n",
    "weather_train_df = pd.read_feather(SETTINGS.data.path_data_root/'weather_train.feather')\n",
    "logging.info(\"Loaded: weather_train_df {}\".format(weather_train_df.shape))\n",
    "r = weather_train_df.head()\n",
    "weather_train_df = reduce_mem_usage(weather_train_df)\n",
    "\n",
    "# Weather test\n",
    "weather_test_df = pd.read_feather(SETTINGS.data.path_data_root/'weather_test.feather')\n",
    "logging.info(\"Loaded: weather_test_df {}\".format(weather_test_df.shape))\n",
    "weather_test_df = reduce_mem_usage(weather_test_df)\n",
    "\n",
    "# Meta\n",
    "building_meta_df = pd.read_feather(SETTINGS.data.path_data_root/'building_metadata.feather')\n",
    "logging.info(\"Loaded: building_meta_df {}\".format(building_meta_df.shape))\n",
    "r = building_meta_df.head()\n",
    "building_meta_df.set_index('building_id',inplace=True, drop=True)\n",
    "building_meta_df = reduce_mem_usage(building_meta_df)\n",
    "\n",
    "# Sample\n",
    "sample_submission = pd.read_feather(os.path.join(SETTINGS.data.path_data_root, 'sample_submission.feather'))\n",
    "logging.info(\"Loaded: sample_submission {}\".format(sample_submission.shape))\n",
    "sample_submission = reduce_mem_usage(sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# train_merge = train_df_data.merge(building_meta_df, on='building_id', how='left')\n",
    "# train_merge.memory_usage().sum() / 1024 ** 2\n",
    "# test_merge = test_df_data.merge(building_meta_df, on='building_id', how='left')\n",
    "# test_merge.memory_usage().sum() / 1024 ** 2\n",
    "#\n",
    "# train_df = train_merge.merge(weather_train_df, on=['site_id', 'timestamp'], how='left')\n",
    "# train_df.memory_usage().sum() / 1024 ** 2\n",
    "# r = train_df.head()\n",
    "#\n",
    "# test_df = test_merge.merge(weather_test_df, on=['site_id', 'timestamp'], how='left')\n",
    "# test_df.memory_usage().sum() / 1024 ** 2\n",
    "# r = test_df.head()\n",
    "\n",
    "# train2.info()\n",
    "\n",
    "# del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_date_time_cols(df):\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "    logging.info(\"Added date column\".format())\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    logging.info(\"Added hour column\".format())\n",
    "    # df[\"day\"] = df[\"timestamp\"].dt.day\n",
    "    df[\"weekend\"] = df[\"timestamp\"].dt.weekday\n",
    "    logging.info(\"Added weekend column\".format())\n",
    "    df[\"month\"] = df[\"timestamp\"].dt.month\n",
    "    logging.info(\"Added month column\".format())\n",
    "    df[\"dayofweek\"] = df[\"timestamp\"].dt.dayofweek\n",
    "    logging.info(\"Added dayofweek column\".format())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Add dates and times"
   },
   "outputs": [],
   "source": [
    "logging.info(\"Adding basic time features to train and test\".format())\n",
    "train_df = preprocess_date_time_cols(train_df)\n",
    "test_df = preprocess_date_time_cols(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "title": "Take the ln transform of the targets"
   },
   "outputs": [],
   "source": [
    "train_df['meter_reading_log1p'] = np.log1p(train_df['meter_reading'])\n",
    "test_df['meter_reading_log1p'] = np.log1p(test_df['meter_reading'])\n",
    "logging.info(\"Added meter_reading_log1p [ln(1+x)] column\".format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    # test_df['building_mean'] = test_df['building_id'].map(building_mean)\n",
    "    test_df['building_median'] = test_df['building_id'].map(building_median)\n",
    "    # test_df['building_min'] = test_df['building_id'].map(building_min)\n",
    "    # test_df['building_max'] = test_df['building_id'].map(building_max)\n",
    "    # test_df['building_std'] = test_df['building_id'].map(building_std)\n",
    "\n",
    "    print('preprocessing weather...')\n",
    "    weather_test_df = weather_test_df.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))\n",
    "    weather_test_df.groupby('site_id').apply(lambda group: group.isna().sum())\n",
    "\n",
    "    # add_lag_feature(weather_test_df, window=3)\n",
    "    # add_lag_feature(weather_test_df, window=72)\n",
    "\n",
    "    print('reduce mem usage...')\n",
    "    reduce_mem_usage(test_df, use_float16=True)\n",
    "    reduce_mem_usage(weather_test_df, use_float16=True)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "    logging.info(\"Removing building site=0\".format())\n",
    "    building_meta_df[building_meta_df.site_id == 0]\n",
    "    train_df = train_df.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')\n",
    "\n",
    "\n",
    "logging.info(\" *** Step 3: Feature engineering *** \".format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "Now, Let's try building GBDT (Gradient Boost Decision Tree) model to predict `meter_reading_log1p`. I will try using LightGBM in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add time feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features introduced in https://www.kaggle.com/ryches/simple-lgbm-solution by @ryches\n",
    "\n",
    "Features that are likely predictive:\n",
    "\n",
    "#### Weather\n",
    "\n",
    "- time of day\n",
    "- holiday\n",
    "- weekend\n",
    "- cloud_coverage + lags\n",
    "- dew_temperature + lags\n",
    "- precip_depth + lags\n",
    "- sea_level_pressure + lags\n",
    "- wind_direction + lags\n",
    "- wind_speed + lags\n",
    "\n",
    "#### Train\n",
    "\n",
    "- max, mean, min, std of the specific building historically\n",
    "\n",
    "\n",
    "\n",
    "However we should be careful of putting time feature, since we have only 1 year data in training,\n",
    "including `date` makes overfiting to training data.\n",
    "\n",
    "How about `month`? It may be better to check performance by cross validation.\n",
    "I go not using this data in this kernel for robust modeling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(SETTINGS)\n",
    "# sort train. i dont know it is best\n",
    "# if use_ucf:\n",
    "#     train_df = train_df.sort_values('month')\n",
    "#     train_df = train_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Adding building_median log1p feature\".format())\n",
    "\n",
    "df_group = train_df.groupby('building_id')['meter_reading_log1p']\n",
    "#building_mean = df_group.mean().astype(np.float16)\n",
    "building_median = df_group.median().astype(np.float16)\n",
    "#building_min = df_group.min().astype(np.float16)\n",
    "#building_max = df_group.max().astype(np.float16)\n",
    "#building_std = df_group.std().astype(np.float16)\n",
    "\n",
    "#train_df['building_mean'] = train_df['building_id'].map(building_mean)\n",
    "train_df['building_median'] = train_df['building_id'].map(building_median)\n",
    "#train_df['building_min'] = train_df['building_id'].map(building_min)\n",
    "#train_df['building_max'] = train_df['building_id'].map(building_max)\n",
    "#train_df['building_std'] = train_df['building_id'].map(building_std)\n",
    "del df_group\n",
    "logging.info(\"Added building_median log1p feature\".format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building_mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill Nan value in weather dataframe by interpolation\n",
    "\n",
    "\n",
    "weather data has a lot of NaNs!!\n",
    "\n",
    "![](http://)I tried to fill these values by **interpolating** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Interpolating over NaNs in weather_train_df\".format())\n",
    "# weather_train_df.groupby('site_id').apply(lambda group: group.isna().sum())\n",
    "weather_train_df = weather_train_df.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# weather_train_df.groupby('site_id').apply(lambda group: group.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems number of nan has reduced by `interpolate` but some property has never appear in specific `site_id`, and nan remains for these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lags\n",
    "\n",
    "Adding some lag feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag_feature(weather_df, window=3):\n",
    "    group_df = weather_df.groupby('site_id')\n",
    "    cols = ['air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed']\n",
    "    rolled = group_df[cols].rolling(window=window, min_periods=0)\n",
    "    lag_mean = rolled.mean().reset_index().astype(np.float16)\n",
    "    lag_max = rolled.max().reset_index().astype(np.float16)\n",
    "    lag_min = rolled.min().reset_index().astype(np.float16)\n",
    "    lag_std = rolled.std().reset_index().astype(np.float16)\n",
    "    for col in cols:\n",
    "        weather_df[f'{col}_mean_lag{window}'] = lag_mean[col]\n",
    "        weather_df[f'{col}_max_lag{window}'] = lag_max[col]\n",
    "        weather_df[f'{col}_min_lag{window}'] = lag_min[col]\n",
    "        weather_df[f'{col}_std_lag{window}'] = lag_std[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip lag feature to save memory\n",
    "#add_lag_feature(weather_train_df, window=3)\n",
    "#add_lag_feature(weather_train_df, window=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize primary_use column to reduce memory on merge...\n",
    "logging.info(\"Convert primary_use to Categorical type\".format())\n",
    "primary_use_list = building_meta_df['primary_use'].unique()\n",
    "primary_use_dict = {key: value for value, key in enumerate(primary_use_list)}\n",
    "print('primary_use_dict: ', primary_use_dict)\n",
    "building_meta_df['primary_use'] = building_meta_df['primary_use'].map(primary_use_dict)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_mem_usage(train_df, use_float16=True)\n",
    "reduce_mem_usage(building_meta_df, use_float16=True)\n",
    "reduce_mem_usage(weather_train_df, use_float16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "building_meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "category_cols = ['building_id', 'site_id', 'primary_use']  # , 'meter'\n",
    "feature_cols = ['square_feet', 'year_built'] + [\n",
    "    'hour', 'weekend',  # 'month' , 'dayofweek'\n",
    "    'building_median'] + [\n",
    "                   'air_temperature', 'cloud_coverage',\n",
    "                   'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure',\n",
    "                   'wind_direction', 'wind_speed', ]\n",
    "\n",
    "\n",
    "#     'air_temperature_mean_lag72',\n",
    "#     'air_temperature_max_lag72', 'air_temperature_min_lag72',\n",
    "#     'air_temperature_std_lag72', 'cloud_coverage_mean_lag72',\n",
    "#     'dew_temperature_mean_lag72', 'precip_depth_1_hr_mean_lag72',\n",
    "#     'sea_level_pressure_mean_lag72', 'wind_direction_mean_lag72',\n",
    "#     'wind_speed_mean_lag72', 'air_temperature_mean_lag3',\n",
    "#     'air_temperature_max_lag3',\n",
    "#     'air_temperature_min_lag3', 'cloud_coverage_mean_lag3',\n",
    "#     'dew_temperature_mean_lag3',\n",
    "#     'precip_depth_1_hr_mean_lag3', 'sea_level_pressure_mean_lag3',\n",
    "#     'wind_direction_mean_lag3', 'wind_speed_mean_lag3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "\n",
    "To win in kaggle competition, how to evaluate your model is important.\n",
    "What kind of cross validation strategy is suitable for this competition? This is time series data, so it is better to consider time-splitting.\n",
    "\n",
    "However this notebook is for simple tutorial, so I will proceed with KFold splitting without shuffling, so that at least near-term data is not included in validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_X_y(train_df, target_meter):\n",
    "    target_train_df = train_df[train_df['meter'] == target_meter]\n",
    "    target_train_df = target_train_df.merge(building_meta_df, on='building_id', how='left')\n",
    "    target_train_df = target_train_df.merge(weather_train_df, on=['site_id', 'timestamp'], how='left')\n",
    "    X_train = target_train_df[feature_cols + category_cols]\n",
    "    y_train = target_train_df['meter_reading_log1p'].values\n",
    "\n",
    "    del target_train_df\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folds = 5\n",
    "seed = 666\n",
    "shuffle = False\n",
    "kf = sk.model_selection.KFold(n_splits=SETTINGS.model.folds, shuffle=shuffle, random_state=seed)\n",
    "oof_total = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model by each meter type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_meter = 0\n",
    "X_train, y_train = create_X_y(train_df, target_meter=target_meter)\n",
    "y_valid_pred_total = np.zeros(X_train.shape[0])\n",
    "gc.collect()\n",
    "print('target_meter', target_meter, X_train.shape)\n",
    "\n",
    "cat_features = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]\n",
    "print('cat_features', cat_features)\n",
    "\n",
    "logging.info(\" *** Step 4: Build model *** \".format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def fit_lgbm(train, val, devices=(-1,), seed=None, cat_features=None, num_rounds=1500, lr=0.1, bf=0.1):\n",
    "    \"\"\"Train Light GBM model\"\"\"\n",
    "    X_train, y_train = train\n",
    "    X_valid, y_valid = val\n",
    "    metric = 'l2'\n",
    "    params = {'num_leaves': 31,\n",
    "              'objective': 'regression',\n",
    "              #               'max_depth': -1,\n",
    "              'learning_rate': lr,\n",
    "              \"boosting\": \"gbdt\",\n",
    "              \"bagging_freq\": 5,\n",
    "              \"bagging_fraction\": bf,\n",
    "              \"feature_fraction\": 0.9,\n",
    "              \"metric\": metric,\n",
    "              #               \"verbosity\": -1,\n",
    "              #               'reg_alpha': 0.1,\n",
    "              #               'reg_lambda': 0.3\n",
    "              }\n",
    "    device = devices[0]\n",
    "    if device == -1:\n",
    "        # use cpu\n",
    "        pass\n",
    "    else:\n",
    "        # use gpu\n",
    "        print(f'using gpu device_id {device}...')\n",
    "        params.update({'device': 'gpu', 'gpu_device_id': device})\n",
    "\n",
    "    params['seed'] = seed\n",
    "\n",
    "    early_stop = 20\n",
    "    verbose_eval = 20\n",
    "\n",
    "    d_train = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_features)\n",
    "    d_valid = lgb.Dataset(X_valid, label=y_valid, categorical_feature=cat_features)\n",
    "    watchlist = [d_train, d_valid]\n",
    "\n",
    "    print('training LGB:')\n",
    "    model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=SETTINGS.model.num_rounds,\n",
    "                      valid_sets=watchlist,\n",
    "                      verbose_eval=verbose_eval,\n",
    "                      early_stopping_rounds=early_stop)\n",
    "\n",
    "    # predictions\n",
    "    y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "\n",
    "    print('best_score', model.best_score)\n",
    "    log = {'train/mae': model.best_score['training']['l2'],\n",
    "           'valid/mae': model.best_score['valid_1']['l2']}\n",
    "    return model, y_pred_valid, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "models0 = []\n",
    "for train_idx, valid_idx in kf.split(X_train, y_train):\n",
    "    train_data = X_train.iloc[train_idx, :], y_train[train_idx]\n",
    "    valid_data = X_train.iloc[valid_idx, :], y_train[valid_idx]\n",
    "\n",
    "    print('train', len(train_idx), 'valid', len(valid_idx))\n",
    "    #     model, y_pred_valid, log = fit_cb(train_data, valid_data, cat_features=cat_features, devices=[0,])\n",
    "    model, y_pred_valid, log = fit_lgbm(train_data, valid_data, cat_features=category_cols,\n",
    "                                        num_rounds=SETTINGS.model.num_rounds, lr=0.05, bf=0.7)\n",
    "    y_valid_pred_total[valid_idx] = y_pred_valid\n",
    "    models0.append(model)\n",
    "    gc.collect()\n",
    "    if SETTINGS.control.debug:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_train)\n",
    "sns.distplot(y_valid_pred_total)\n",
    "\n",
    "oof0 = sk.metrics.mean_squared_error(y_train, y_valid_pred_total)\n",
    "oof_total += oof0 * len(y_train)\n",
    "\n",
    "del X_train, y_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def plot_feature_importance(model):\n",
    "    importance_df = pd.DataFrame(model.feature_importance(),\n",
    "                                 index=feature_cols + category_cols,\n",
    "                                 columns=['importance']).sort_values('importance')\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    importance_df.plot.barh(ax=ax)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_meter = 1\n",
    "X_train, y_train = create_X_y(train_df, target_meter=target_meter)\n",
    "y_valid_pred_total = np.zeros(X_train.shape[0])\n",
    "gc.collect()\n",
    "print('target_meter', target_meter, X_train.shape)\n",
    "\n",
    "cat_features = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]\n",
    "print('cat_features', cat_features)\n",
    "\n",
    "models1 = []\n",
    "for train_idx, valid_idx in kf.split(X_train, y_train):\n",
    "    train_data = X_train.iloc[train_idx ,:], y_train[train_idx]\n",
    "    valid_data = X_train.iloc[valid_idx ,:], y_train[valid_idx]\n",
    "\n",
    "    print('train', len(train_idx), 'valid', len(valid_idx))\n",
    "    #     model, y_pred_valid, log = fit_cb(train_data, valid_data, cat_features=cat_features, devices=[0,])\n",
    "    model, y_pred_valid, log = fit_lgbm(train_data, valid_data, cat_features=category_cols, num_rounds=SETTINGS.model.num_rounds,\n",
    "                                        lr=0.05, bf=0.5)\n",
    "    y_valid_pred_total[valid_idx] = y_pred_valid\n",
    "    models1.append(model)\n",
    "    gc.collect()\n",
    "    if SETTINGS.control.debug:\n",
    "        break\n",
    "\n",
    "sns.distplot(y_train)\n",
    "sns.distplot(y_valid_pred_total)\n",
    "\n",
    "oof1 = sk.metrics.mean_squared_error(y_train, y_valid_pred_total)\n",
    "oof_total += oof1 * len(y_train)\n",
    "\n",
    "del X_train, y_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_meter = 2\n",
    "X_train, y_train = create_X_y(train_df, target_meter=target_meter)\n",
    "y_valid_pred_total = np.zeros(X_train.shape[0])\n",
    "\n",
    "gc.collect()\n",
    "print('target_meter', target_meter, X_train.shape)\n",
    "\n",
    "cat_features = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]\n",
    "print('cat_features', cat_features)\n",
    "\n",
    "models2 = []\n",
    "for train_idx, valid_idx in kf.split(X_train, y_train):\n",
    "    train_data = X_train.iloc[train_idx ,:], y_train[train_idx]\n",
    "    valid_data = X_train.iloc[valid_idx ,:], y_train[valid_idx]\n",
    "\n",
    "    print('train', len(train_idx), 'valid', len(valid_idx))\n",
    "    #     model, y_pred_valid, log = fit_cb(train_data, valid_data, cat_features=cat_features, devices=[0,])\n",
    "    model, y_pred_valid, log = fit_lgbm(train_data, valid_data, cat_features=category_cols,\n",
    "                                        num_rounds=SETTINGS.model.num_rounds, lr=0.05, bf=0.8)\n",
    "    y_valid_pred_total[valid_idx] = y_pred_valid\n",
    "    models2.append(model)\n",
    "    gc.collect()\n",
    "    if SETTINGS.control.debug:\n",
    "        break\n",
    "\n",
    "sns.distplot(y_train)\n",
    "sns.distplot(y_valid_pred_total)\n",
    "\n",
    "oof2 = sk.metrics.mean_squared_error(y_train, y_valid_pred_total)\n",
    "oof_total += oof2 * len(y_train)\n",
    "\n",
    "del X_train, y_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_meter = 3\n",
    "X_train, y_train = create_X_y(train_df, target_meter=target_meter)\n",
    "y_valid_pred_total = np.zeros(X_train.shape[0])\n",
    "\n",
    "gc.collect()\n",
    "print('target_meter', target_meter, X_train.shape)\n",
    "\n",
    "cat_features = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]\n",
    "print('cat_features', cat_features)\n",
    "\n",
    "models3 = []\n",
    "for train_idx, valid_idx in kf.split(X_train, y_train):\n",
    "    train_data = X_train.iloc[train_idx ,:], y_train[train_idx]\n",
    "    valid_data = X_train.iloc[valid_idx ,:], y_train[valid_idx]\n",
    "\n",
    "    print('train', len(train_idx), 'valid', len(valid_idx))\n",
    "    #     model, y_pred_valid, log = fit_cb(train_data, valid_data, cat_features=cat_features, devices=[0,])\n",
    "    model, y_pred_valid, log = fit_lgbm(train_data, valid_data, cat_features=category_cols, num_rounds=SETTINGS.model.num_rounds,\n",
    "                                        lr=0.03, bf=0.9)\n",
    "    y_valid_pred_total[valid_idx] = y_pred_valid\n",
    "    models3.append(model)\n",
    "    gc.collect()\n",
    "    if SETTINGS.control.debug:\n",
    "        break\n",
    "\n",
    "sns.distplot(y_train)\n",
    "sns.distplot(y_valid_pred_total)\n",
    "\n",
    "oof3 = sk.metrics.mean_squared_error(y_train, y_valid_pred_total)\n",
    "oof_total += oof3 * len(y_train)\n",
    "\n",
    "del X_train, y_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# OOF SCOREs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('oof score meter0 =', np.sqrt(oof0))\n",
    "print ('oof score meter1 =', np.sqrt(oof1))\n",
    "print ('oof score meter2 =', np.sqrt(oof2))\n",
    "print ('oof score meter3 =', np.sqrt(oof3))\n",
    "print ('oof score total  =', np.sqrt(oof_total / len(train_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "del train_df, weather_train_df, building_meta_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def create_X(test_df, target_meter):\n",
    "    target_test_df = test_df[test_df['meter'] == target_meter]\n",
    "    target_test_df = target_test_df.merge(building_meta_df, on='building_id', how='left')\n",
    "    target_test_df = target_test_df.merge(weather_test_df, on=['site_id', 'timestamp'], how='left')\n",
    "    X_test = target_test_df[feature_cols + category_cols]\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def pred(X_test, models, batch_size=1000000):\n",
    "    iterations = (X_test.shape[0] + batch_size -1) // batch_size\n",
    "    print('iterations', iterations)\n",
    "\n",
    "    y_test_pred_total = np.zeros(X_test.shape[0])\n",
    "    for i, model in enumerate(models):\n",
    "        print(f'predicting {i}-th model')\n",
    "        for k in tqdm.tqdm(range(iterations)):\n",
    "            y_pred_test = model.predict(X_test[k * batch_size:(k + 1) * batch_size], num_iteration=model.best_iteration)\n",
    "            y_test_pred_total[k * batch_size:(k + 1) * batch_size] += y_pred_test\n",
    "\n",
    "    y_test_pred_total /= len(models)\n",
    "    return y_test_pred_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test = create_X(test_df, target_meter=0)\n",
    "gc.collect()\n",
    "\n",
    "y_test0 = pred(X_test, models0)\n",
    "\n",
    "sns.distplot(y_test0)\n",
    "\n",
    "del X_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test = create_X(test_df, target_meter=1)\n",
    "gc.collect()\n",
    "\n",
    "y_test1 = pred(X_test, models1)\n",
    "sns.distplot(y_test1)\n",
    "\n",
    "del X_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test = create_X(test_df, target_meter=2)\n",
    "gc.collect()\n",
    "\n",
    "y_test2 = pred(X_test, models2)\n",
    "sns.distplot(y_test2)\n",
    "\n",
    "del X_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = create_X(test_df, target_meter=3)\n",
    "gc.collect()\n",
    "\n",
    "y_test3 = pred(X_test, models3)\n",
    "sns.distplot(y_test3)\n",
    "\n",
    "del X_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.loc[test_df['meter'] == 0, 'meter_reading'] = np.expm1(y_test0)\n",
    "sample_submission.loc[test_df['meter'] == 1, 'meter_reading'] = np.expm1(y_test1)\n",
    "sample_submission.loc[test_df['meter'] == 2, 'meter_reading'] = np.expm1(y_test2)\n",
    "sample_submission.loc[test_df['meter'] == 3, 'meter_reading'] = np.expm1(y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(SETTINGS.data.path_output / 'submission.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace to UCF data\n",
    "if 0:\n",
    "    # %%\n",
    "    leak_score = 0\n",
    "\n",
    "    leak_df = pd.read_pickle(ucf_root / 'site0.pkl')\n",
    "    leak_df['meter_reading'] = leak_df.meter_reading_scraped\n",
    "    leak_df.drop(['meter_reading_original', 'meter_reading_scraped'], axis=1, inplace=True)\n",
    "    leak_df.fillna(0, inplace=True)\n",
    "    leak_df = leak_df[leak_df.timestamp.dt.year > 2016]\n",
    "    leak_df.loc[leak_df.meter_reading < 0, 'meter_reading'] = 0  # remove large negative values\n",
    "\n",
    "    sample_submission.loc[sample_submission.meter_reading < 0, 'meter_reading'] = 0\n",
    "\n",
    "    for bid in leak_df.building_id.unique():\n",
    "        temp_df = leak_df[(leak_df.building_id == bid)]\n",
    "        for m in temp_df.meter.unique():\n",
    "            v0 = sample_submission.loc[(test_df.building_id == bid) & (test_df.meter == m), 'meter_reading'].values\n",
    "            v1 = temp_df[temp_df.meter == m].meter_reading.values\n",
    "\n",
    "            leak_score += sk.metrics.mean_squared_error(np.log1p(v0), np.log1p(v1)) * len(v0)\n",
    "\n",
    "            sample_submission.loc[(test_df.building_id == bid) & (test_df.meter == m), 'meter_reading'] = temp_df[\n",
    "                temp_df.meter == m].meter_reading.values\n",
    "\n",
    "    # %%\n",
    "    if not SETTINGS.control.debug:\n",
    "        sample_submission.to_csv('submission_ucf_replaced.csv', index=False, float_format='%.4f')\n",
    "\n",
    "    # %%\n",
    "    sample_submission.head()\n",
    "\n",
    "    # %%\n",
    "    np.log1p(sample_submission['meter_reading']).hist()\n",
    "\n",
    "    # %% [markdown]\n",
    "    # # UCF score\n",
    "\n",
    "    # %%\n",
    "    print('UCF score = ', np.sqrt(leak_score / len(leak_df)))\n",
    "\n",
    "    # %%\n",
    "    plot_feature_importance(models0[1])\n",
    "\n",
    "    # %%\n",
    "    plot_feature_importance(models1[1])\n",
    "\n",
    "    # %%\n",
    "    plot_feature_importance(models2[1])\n",
    "\n",
    "    # %%\n",
    "    plot_feature_importance(models3[1])\n",
    "\n",
    "    # %% [markdown]\n",
    "    # # References\n",
    "    #\n",
    "    # These kernels inspired me to write this kernel, thank you for sharing!\n",
    "    #\n",
    "    #  - https://www.kaggle.com/rishabhiitbhu/ashrae-simple-eda\n",
    "    #  - https://www.kaggle.com/isaienkov/simple-lightgbm\n",
    "    #  - https://www.kaggle.com/ryches/simple-lgbm-solution"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,_kg_hide-input,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "kaggle_ashrae_dsr",
   "language": "python",
   "name": "kaggle_ashrae_dsr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
